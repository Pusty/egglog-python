{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Implenting an Array API to use with Scikit-learn\n",
    "\n",
    "\n",
    "In this tutorial, we will create an object that implements the Array API and use it in the `LinearDiscriminantAnalysis` example that is in the [scikit-learn docs](https://scikit-learn.org/stable/modules/array_api.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try LDA with normal numpy arrays.\n",
    "\n",
    "We take a set of input vector and reduce the dimensionality to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import config_context\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "def fit(X, y):\n",
    "    with config_context(array_api_dispatch=True):\n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        X_r2 = lda.fit(X, y).transform(X)\n",
    "        return X_r2\n",
    "\n",
    "    target_names = iris.target_names\n",
    "    plt.figure()\n",
    "    colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
    "\n",
    "    plt.figure()\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "        plt.scatter(\n",
    "            X_r2[y == i, 0], X_r2[y == i, 1], alpha=0.8, color=color, label=target_name\n",
    "        )\n",
    "    plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "    plt.title(\"LDA of IRIS dataset\")\n",
    "\n",
    "    plt.show()\n",
    "# fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# fit(torch.asarray(X), torch.asarray(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to make a NDArray object that implements the Array API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isdtype(DType.float32, IsDtypeKind.string(\"integral\"))\n",
      "  -> FALSE\n",
      "     -> FALSE\n",
      "DType.float64 == NDArray.var(\"X\").dtype\n",
      "  -> DType.float64 == NDArray.var(\"X\").dtype\n",
      "     -> TRUE\n",
      "asarray(NDArray.var(\"X\")).ndim == Int(0)\n",
      "  -> NDArray.var(\"X\").ndim == Int(0)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).ndim == Int(1)\n",
      "  -> NDArray.var(\"X\").ndim == Int(1)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).ndim >= Int(3)\n",
      "  -> NDArray.var(\"X\").ndim >= Int(3)\n",
      "     -> FALSE\n",
      "asarray(asarray(NDArray.var(\"X\"))).dtype == DType.object\n",
      "  -> NDArray.var(\"X\").dtype == DType.object\n",
      "     -> FALSE\n",
      "isdtype(asarray(asarray(NDArray.var(\"X\"))).dtype, (IsDtypeKind.string(\"real floating\") | (IsDtypeKind.string(\"complex floating\") | IsDtypeKind.NULL)))\n",
      "  -> isdtype(NDArray.var(\"X\").dtype, (IsDtypeKind.string(\"real floating\") | IsDtypeKind.string(\"complex floating\")))\n",
      "     -> TRUE\n",
      "isfinite(sum(asarray(asarray(NDArray.var(\"X\"))))).bool()\n",
      "  -> isfinite(sum(NDArray.var(\"X\"))).bool()\n",
      "     -> TRUE\n",
      "asarray(NDArray.var(\"X\")).shape.length()\n",
      "  -> NDArray.var(\"X\").ndim\n",
      "     -> Int(2)\n",
      "asarray(NDArray.var(\"X\")).shape[Int(0)] < Int(2)\n",
      "  -> NDArray.var(\"X\").shape[Int(0)] < Int(2)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).ndim == Int(2)\n",
      "  -> NDArray.var(\"X\").ndim == Int(2)\n",
      "     -> TRUE\n",
      "asarray(NDArray.var(\"X\")).shape[Int(1)] < Int(1)\n",
      "  -> NDArray.var(\"X\").shape[Int(1)] < Int(1)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"y\")).ndim >= Int(3)\n",
      "  -> NDArray.var(\"y\").ndim >= Int(3)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"y\")).ndim == Int(2)\n",
      "  -> NDArray.var(\"y\").ndim == Int(2)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"y\")).shape.length()\n",
      "  -> NDArray.var(\"y\").ndim\n",
      "     -> Int(1)\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).dtype == DType.object\n",
      "  -> NDArray.var(\"y\").dtype == DType.object\n",
      "     -> FALSE\n",
      "isdtype(\n",
      "    asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).dtype,\n",
      "    (IsDtypeKind.string(\"real floating\") | (IsDtypeKind.string(\"complex floating\") | IsDtypeKind.NULL)),\n",
      ")\n",
      "  -> isdtype(NDArray.var(\"y\").dtype, (IsDtypeKind.string(\"real floating\") | IsDtypeKind.string(\"complex floating\")))\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).shape.length()\n",
      "  -> NDArray.var(\"X\").ndim\n",
      "     -> Int(2)\n",
      "asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))).shape.length()\n",
      "  -> Int(1)\n",
      "     -> Int(1)\n",
      "asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))).shape[Int(0)] < asarray(NDArray.var(\"X\")).shape[Int(0)]\n",
      "  -> NDArray.var(\"y\").size < NDArray.var(\"X\").shape[Int(0)]\n",
      "     -> FALSE\n",
      "asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))).shape[Int(0)] > asarray(NDArray.var(\"X\")).shape[Int(0)]\n",
      "  -> NDArray.var(\"y\").size > NDArray.var(\"X\").shape[Int(0)]\n",
      "     -> FALSE\n",
      "asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))).shape[Int(0)] == asarray(NDArray.var(\"X\")).shape[Int(0)]\n",
      "  -> NDArray.var(\"y\").size == NDArray.var(\"X\").shape[Int(0)]\n",
      "     -> TRUE\n",
      "asarray(NDArray.var(\"X\")).shape.length()\n",
      "  -> NDArray.var(\"X\").ndim\n",
      "     -> Int(2)\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).ndim == Int(2)\n",
      "  -> FALSE\n",
      "     -> FALSE\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).ndim == Int(1)\n",
      "  -> TRUE\n",
      "     -> TRUE\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).shape.length()\n",
      "  -> Int(1)\n",
      "     -> Int(1)\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).shape[Int(0)] == Int(0)\n",
      "  -> NDArray.var(\"y\").size == Int(0)\n",
      "     -> FALSE\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).dtype == DType.object\n",
      "  -> NDArray.var(\"y\").dtype == DType.object\n",
      "     -> FALSE\n",
      "asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).ndim == Int(2)\n",
      "  -> FALSE\n",
      "     -> FALSE\n",
      "isdtype(asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).dtype, IsDtypeKind.string(\"real floating\"))\n",
      "  -> isdtype(NDArray.var(\"y\").dtype, IsDtypeKind.string(\"real floating\"))\n",
      "     -> FALSE\n",
      "unique_values(asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))))).shape[Int(0)] > Int(2)\n",
      "  -> unique_values(reshape(NDArray.var(\"y\"), TupleInt(Int(-1)))).shape[Int(0)] > Int(2)\n",
      "     -> TRUE\n",
      "asarray(NDArray.var(\"X\")).shape.length()\n",
      "  -> NDArray.var(\"X\").ndim\n",
      "     -> Int(2)\n",
      "asarray(NDArray.var(\"X\")).shape[Int(0)] == unique_values(\n",
      "    concat((TupleNDArray(unique_values(asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))))) + TupleNDArray.EMPTY))\n",
      ").shape[Int(0)]\n",
      "  -> NDArray.var(\"X\").shape[Int(0)] == unique_values(reshape(NDArray.var(\"y\"), TupleInt(Int(-1)))).shape[Int(0)]\n",
      "     -> FALSE\n",
      "unique_counts(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).length()\n",
      "  -> Int(2)\n",
      "     -> Int(2)\n",
      "asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))).shape[Int(0)]\n",
      "  -> NDArray.var(\"y\").size\n",
      "     -> Int(150)\n",
      "any(\n",
      "    (\n",
      "        (\n",
      "            astype(unique_counts(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))))[Int(1)], asarray(NDArray.var(\"X\")).dtype)\n",
      "            / NDArray.scalar_float(Float(150.0))\n",
      "        )\n",
      "        < NDArray.scalar_int(Int(0))\n",
      "    )\n",
      ").bool()\n",
      "  -> FALSE\n",
      "     -> FALSE\n",
      "(\n",
      "    abs(\n",
      "        (\n",
      "            sum(\n",
      "                (\n",
      "                    astype(unique_counts(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))))[Int(1)], asarray(NDArray.var(\"X\")).dtype)\n",
      "                    / NDArray.scalar_float(Float(150.0))\n",
      "                )\n",
      "            )\n",
      "            - NDArray.scalar_float(Float(1.0))\n",
      "        )\n",
      "    )\n",
      "    > NDArray.scalar_float(Float(1e-05))\n",
      ").bool()\n",
      "  -> (\n",
      "    abs(\n",
      "        (\n",
      "            (astype(NDArray.scalar_int(reshape(NDArray.var(\"y\"), TupleInt(Int(-1))).size), NDArray.var(\"X\").dtype) / NDArray.scalar_float(Float(150.0)))\n",
      "            - NDArray.scalar_float(Float(1.0))\n",
      "        )\n",
      "    )\n",
      "    > NDArray.scalar_float(Float(1e-05))\n",
      ").bool()\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).shape[Int(1)] < (\n",
      "    unique_values(concat((TupleNDArray(unique_values(asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))))) + TupleNDArray.EMPTY))).shape[\n",
      "        Int(0)\n",
      "    ]\n",
      "    - Int(1)\n",
      ")\n",
      "  -> NDArray.var(\"X\").shape[Int(1)] < (unique_values(reshape(NDArray.var(\"y\"), TupleInt(Int(-1)))).shape[Int(0)] - Int(1))\n",
      "     -> FALSE\n",
      "(\n",
      "    unique_values(concat((TupleNDArray(unique_values(asarray(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))))) + TupleNDArray.EMPTY))).shape[\n",
      "        Int(0)\n",
      "    ]\n",
      "    - Int(1)\n",
      ") < Int(2)\n",
      "  -> (unique_values(reshape(NDArray.var(\"y\"), TupleInt(Int(-1)))).shape[Int(0)] - Int(1)) < Int(2)\n",
      "     -> FALSE\n",
      "asarray(NDArray.var(\"X\")).shape.length()\n",
      "  -> NDArray.var(\"X\").ndim\n",
      "     -> Int(2)\n",
      "unique_inverse(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY)))).length()\n",
      "  -> Int(2)\n",
      "     -> Int(2)\n",
      "unique_inverse(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))))[Int(0)].shape[Int(0)]\n",
      "unique_inverse(asarray(reshape(asarray(NDArray.var(\"y\")), (TupleInt(Int(-1)) + TupleInt.EMPTY))))[Int(0)].shape[Int(0)]\n",
      "  -> unique_values(reshape(NDArray.var(\"y\"), TupleInt(Int(-1)))).shape[Int(0)]\n",
      "     -> Int(3)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Class NDArray does not have method __eq__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/p/egg-smol-python/python/egglog/runtime.py:388\u001b[0m, in \u001b[0;36m_special_method\u001b[0;34m(self, __name, *args)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_decls__\u001b[39m.\u001b[39;49mget_class_decl(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_typed_expr__\u001b[39m.\u001b[39;49mtp\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49mpreserved_methods[__name]\n\u001b[1;32m    389\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '__eq__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/p/egg-smol-python/python/egglog/runtime.py:318\u001b[0m, in \u001b[0;36mRuntimeMethod.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_fn_decl__ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_decls__\u001b[39m.\u001b[39;49mget_function_decl(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_callable_ref__)\n\u001b[1;32m    319\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/p/egg-smol-python/python/egglog/declarations.py:192\u001b[0m, in \u001b[0;36mModuleDeclarations.get_function_decl\u001b[0;34m(self, ref)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFunction \u001b[39m\u001b[39m{\u001b[39;00mref\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Function MethodRef(class_name='NDArray', method_name='__eq__') not found\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 700\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[39m# Add values for the constants\u001b[39;00m\n\u001b[1;32m    687\u001b[0m egraph\u001b[39m.\u001b[39mregister(\n\u001b[1;32m    688\u001b[0m     rewrite(X_arr\u001b[39m.\u001b[39mdtype, runtime_ruleset)\u001b[39m.\u001b[39mto(convert(X\u001b[39m.\u001b[39mdtype, DType)),\n\u001b[1;32m    689\u001b[0m     rewrite(y_arr\u001b[39m.\u001b[39mdtype, runtime_ruleset)\u001b[39m.\u001b[39mto(convert(y\u001b[39m.\u001b[39mdtype, DType)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m     rewrite(unique_values(y_arr)\u001b[39m.\u001b[39mshape)\u001b[39m.\u001b[39mto(TupleInt(Int(\u001b[39m3\u001b[39m))),\n\u001b[1;32m    697\u001b[0m )\n\u001b[0;32m--> 700\u001b[0m res \u001b[39m=\u001b[39m fit(X_arr, y_arr)\n\u001b[1;32m    702\u001b[0m \u001b[39m# X_obj, y_obj = egraph.save_object(X), egraph.save_object(y)\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \n\u001b[1;32m    704\u001b[0m \u001b[39m# X_arr = NDArray(X_obj)\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39m# y_arr = NDArray(y_obj)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m config_context(array_api_dispatch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m     lda \u001b[39m=\u001b[39m LinearDiscriminantAnalysis(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     X_r2 \u001b[39m=\u001b[39m lda\u001b[39m.\u001b[39;49mfit(X, y)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m X_r2\n\u001b[1;32m     18\u001b[0m target_names \u001b[39m=\u001b[39m iris\u001b[39m.\u001b[39mtarget_names\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/egg-smol-python/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/egg-smol-python/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:629\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance_estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    625\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcovariance estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith svd solver. Try another solver\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m         )\n\u001b[0;32m--> 629\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_solve_svd(X, y)\n\u001b[1;32m    630\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlsqr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_solve_lstsq(\n\u001b[1;32m    632\u001b[0m         X,\n\u001b[1;32m    633\u001b[0m         y,\n\u001b[1;32m    634\u001b[0m         shrinkage\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshrinkage,\n\u001b[1;32m    635\u001b[0m         covariance_estimator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance_estimator,\n\u001b[1;32m    636\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/egg-smol-python/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:501\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis._solve_svd\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    498\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    499\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 501\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeans_ \u001b[39m=\u001b[39m _class_means(X, y)\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_covariance:\n\u001b[1;32m    503\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance_ \u001b[39m=\u001b[39m _class_cov(X, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpriors_)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/egg-smol-python/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:121\u001b[0m, in \u001b[0;36m_class_means\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39mprint\u001b[39m(classes\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    120\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(classes\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 121\u001b[0m         means[i, :] \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mmean(X[y \u001b[39m==\u001b[39;49m i], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[39m# TODO: Explore the choice of using bincount + add.at as it seems sub optimal\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[39m# from a performance-wise\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     cnt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y)\n",
      "File \u001b[0;32m~/p/egg-smol-python/python/egglog/runtime.py:390\u001b[0m, in \u001b[0;36m_special_method\u001b[0;34m(self, __name, *args)\u001b[0m\n\u001b[1;32m    388\u001b[0m     method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_decls__\u001b[39m.\u001b[39mget_class_decl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_typed_expr__\u001b[39m.\u001b[39mtp\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mpreserved_methods[__name]\n\u001b[1;32m    389\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m RuntimeMethod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_decls__, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__egg_typed_expr__, __name)(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    391\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, __egg_decls__, __egg_typed_expr__, __egg_method_name__)\u001b[0m\n",
      "File \u001b[0;32m~/p/egg-smol-python/python/egglog/runtime.py:320\u001b[0m, in \u001b[0;36mRuntimeMethod.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_fn_decl__ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_decls__\u001b[39m.\u001b[39mget_function_decl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_callable_ref__)\n\u001b[1;32m    319\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClass \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_name\u001b[39m}\u001b[39;00m\u001b[39m does not have method \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__egg_method_name__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Class NDArray does not have method __eq__"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "from typing import TypeVar, ClassVar, Any\n",
    "import itertools\n",
    "from egglog.egraph import Unit\n",
    "import numpy as np\n",
    "import numbers\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from egglog import *\n",
    "\n",
    "# Pretend that exprs are numbers b/c scikit learn does isinstance checks\n",
    "from egglog.runtime import RuntimeExpr\n",
    "\n",
    "numbers.Integral.register(RuntimeExpr)\n",
    "\n",
    "egraph = EGraph()\n",
    "\n",
    "T = TypeVar(\"T\", bound=Expr)\n",
    "\n",
    "runtime_ruleset = egraph.ruleset(\"runtime\")\n",
    "\n",
    "\n",
    "def extract_py(e: Expr) -> Any:\n",
    "    print(e)\n",
    "    egraph.register(e)\n",
    "    egraph.run(run(limit=10).saturate())\n",
    "    final_object = egraph.extract(e)\n",
    "    print(f\"  -> {final_object}\")\n",
    "    with egraph:\n",
    "        egraph.run((run(runtime_ruleset, limit=10) + run(limit=10)).saturate())\n",
    "        print(f\"     -> {egraph.extract(final_object)}\")\n",
    "        res = egraph.load_object(egraph.extract(final_object.to_py()))\n",
    "        return res\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class Bool(Expr):\n",
    "    @egraph.method(preserve=True)\n",
    "    def __bool__(self) -> bool:\n",
    "        return extract_py(self)\n",
    "\n",
    "    def to_py(self) -> PyObject:\n",
    "        ...\n",
    "\n",
    "    def __or__(self, other: Bool) -> Bool:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(bool, Bool, lambda x: TRUE if x else FALSE)\n",
    "\n",
    "TRUE = egraph.constant(\"TRUE\", Bool)\n",
    "FALSE = egraph.constant(\"FALSE\", Bool)\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _bool(x: Bool):\n",
    "    return [\n",
    "        set_(TRUE.to_py()).to(egraph.save_object(True)),\n",
    "        set_(FALSE.to_py()).to(egraph.save_object(False)),\n",
    "        rewrite(TRUE | x).to(TRUE),\n",
    "        rewrite(FALSE | x).to(x),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class DType(Expr):\n",
    "    float64: ClassVar[DType]\n",
    "    float32: ClassVar[DType]\n",
    "    int64: ClassVar[DType]\n",
    "    object: ClassVar[DType]\n",
    "\n",
    "    def __eq__(self, other: DType) -> Bool:\n",
    "        ...\n",
    "\n",
    "\n",
    "float64 = DType.float64\n",
    "float32 = DType.float32\n",
    "int64 = DType.int64\n",
    "\n",
    "converter(type, DType, lambda x: convert(np.dtype(x), DType))\n",
    "converter(type(np.dtype), DType, lambda x: getattr(DType, x.name))\n",
    "egraph.register(\n",
    "    *(\n",
    "        rewrite(l == r).to(TRUE if expr_parts(l) == expr_parts(r) else FALSE)\n",
    "        for l, r in itertools.product([DType.float64, DType.float32, DType.object, DType.int64], repeat=2)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class IsDtypeKind(Expr):\n",
    "    NULL: ClassVar[IsDtypeKind]\n",
    "\n",
    "    @classmethod\n",
    "    def string(cls, s: StringLike) -> IsDtypeKind:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def dtype(cls, d: DType) -> IsDtypeKind:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(cost=10)\n",
    "    def __or__(self, other: IsDtypeKind) -> IsDtypeKind:\n",
    "        ...\n",
    "\n",
    "\n",
    "# TODO: Make kind more generic to support tuples.\n",
    "@egraph.function\n",
    "def isdtype(dtype: DType, kind: IsDtypeKind) -> Bool:\n",
    "    ...\n",
    "\n",
    "\n",
    "converter(np.dtype, IsDtypeKind, lambda x: IsDtypeKind.dtype(convert(x, DType)))\n",
    "converter(DType, IsDtypeKind, lambda x: IsDtypeKind.dtype(x))\n",
    "converter(str, IsDtypeKind, lambda x: IsDtypeKind.string(x))\n",
    "converter(\n",
    "    tuple, IsDtypeKind, lambda x: convert(x[0], IsDtypeKind) | convert(x[1:], IsDtypeKind) if x else IsDtypeKind.NULL\n",
    ")\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _isdtype(d: DType, k1: IsDtypeKind, k2: IsDtypeKind):\n",
    "    return [\n",
    "        rewrite(isdtype(DType.float32, IsDtypeKind.string(\"integral\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.float64, IsDtypeKind.string(\"integral\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.object, IsDtypeKind.string(\"integral\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.int64, IsDtypeKind.string(\"integral\"))).to(TRUE),\n",
    "        rewrite(isdtype(DType.float32, IsDtypeKind.string(\"real floating\"))).to(TRUE),\n",
    "        rewrite(isdtype(DType.float64, IsDtypeKind.string(\"real floating\"))).to(TRUE),\n",
    "        rewrite(isdtype(DType.object, IsDtypeKind.string(\"real floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.int64, IsDtypeKind.string(\"real floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.float32, IsDtypeKind.string(\"complex floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.float64, IsDtypeKind.string(\"complex floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.object, IsDtypeKind.string(\"complex floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(DType.int64, IsDtypeKind.string(\"complex floating\"))).to(FALSE),\n",
    "        rewrite(isdtype(d, IsDtypeKind.NULL)).to(FALSE),\n",
    "        rewrite(isdtype(d, IsDtypeKind.dtype(d))).to(TRUE),\n",
    "        rewrite(isdtype(d, k1 | k2)).to(isdtype(d, k1) | isdtype(d, k2)),\n",
    "        rewrite(k1 | IsDtypeKind.NULL).to(k1),\n",
    "    ]\n",
    "\n",
    "\n",
    "assert not bool(isdtype(DType.float32, IsDtypeKind.string(\"integral\")))\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class Float(Expr):\n",
    "    def __init__(self, value: f64Like) -> None:\n",
    "        ...\n",
    "\n",
    "    def abs(self) -> Float:\n",
    "        ...\n",
    "\n",
    "converter(float, Float, lambda x: Float(x))\n",
    "\n",
    "@egraph.register\n",
    "def _float(f: f64, f2: f64, r: Bool, o: Float):\n",
    "    return [\n",
    "        rewrite(Float(f).abs()).to(Float(f), f >= 0.0),\n",
    "        rewrite(Float(f).abs()).to(Float(-f), f < 0.0),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class Int(Expr):\n",
    "    def __init__(self, value: i64Like) -> None:\n",
    "        ...\n",
    "\n",
    "    # Make != always return a Bool, so that numpy.unique works on a tuple of ints\n",
    "    # In _unique1d\n",
    "    @egraph.method(preserve=True)\n",
    "    def __ne__(self, other: Int) -> bool:\n",
    "        return not extract_py(self == other)\n",
    "\n",
    "    def __eq__(self, other: Int) -> Bool:\n",
    "        ...\n",
    "\n",
    "    def __ge__(self, other: Int) -> Bool:\n",
    "        ...\n",
    "\n",
    "    def __lt__(self, other: Int) -> Bool:\n",
    "        ...\n",
    "\n",
    "    def __gt__(self, other: Int) -> Bool:\n",
    "        ...\n",
    "\n",
    "    def __add__(self, other: Int) -> Int:\n",
    "        ...\n",
    "    def __sub__(self, other: Int) -> Int: ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __int__(self) -> int:\n",
    "        return extract_py(self)\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __index__(self) -> int:\n",
    "        return extract_py(self)\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __float__(self) -> float:\n",
    "        return float(int(self))\n",
    "\n",
    "    def to_py(self) -> PyObject:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __bool__(self) -> bool:\n",
    "        return self != Int(0)\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _int(i: i64, j: i64, r: Bool, o: Int):\n",
    "    yield rewrite(Int(i) == Int(i)).to(TRUE)\n",
    "    yield rule(eq(r).to(Int(i) == Int(j)), i != j).then(union(r).with_(FALSE))\n",
    "\n",
    "    yield rewrite(Int(i) >= Int(i)).to(TRUE)\n",
    "    yield rule(eq(r).to(Int(i) >= Int(j)), i > j).then(union(r).with_(TRUE))\n",
    "    yield rule(eq(r).to(Int(i) >= Int(j)), i < j).then(union(r).with_(FALSE))\n",
    "\n",
    "    yield rewrite(Int(i) < Int(i)).to(FALSE)\n",
    "    yield rule(eq(r).to(Int(i) < Int(j)), i < j).then(union(r).with_(TRUE))\n",
    "    yield rule(eq(r).to(Int(i) < Int(j)), i > j).then(union(r).with_(FALSE))\n",
    "\n",
    "    yield rewrite(Int(i) > Int(i)).to(FALSE)\n",
    "    yield rule(eq(r).to(Int(i) > Int(j)), i > j).then(union(r).with_(TRUE))\n",
    "    yield rule(eq(r).to(Int(i) > Int(j)), i < j).then(union(r).with_(FALSE))\n",
    "\n",
    "    yield rule(eq(o).to(Int(j))).then(set_(o.to_py()).to(PyObject.from_int(j)))\n",
    "\n",
    "    yield rewrite(Int(i) + Int(j)).to(Int(i + j))\n",
    "    yield rewrite(Int(i) - Int(j)).to(Int(i - j))\n",
    "\n",
    "\n",
    "converter(int, Int, lambda x: Int(x))\n",
    "\n",
    "assert expr_parts(egraph.simplify(Int(1) == Int(1), 10)) == expr_parts(TRUE)\n",
    "assert expr_parts(egraph.simplify(Int(1) == Int(2), 10)) == expr_parts(FALSE)\n",
    "assert expr_parts(egraph.simplify(Int(1) >= Int(2), 10)) == expr_parts(FALSE)\n",
    "assert expr_parts(egraph.simplify(Int(1) >= Int(1), 10)) == expr_parts(TRUE)\n",
    "assert expr_parts(egraph.simplify(Int(2) >= Int(1), 10)) == expr_parts(TRUE)\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class TupleInt(Expr):\n",
    "    EMPTY: ClassVar[TupleInt]\n",
    "\n",
    "    def __init__(self, head: Int) -> None:\n",
    "        ...\n",
    "\n",
    "    def __add__(self, other: TupleInt) -> TupleInt:\n",
    "        ...\n",
    "\n",
    "    def length(self) -> Int:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.length())\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __iter__(self):\n",
    "        return iter(self[Int(i)] for i in range(len(self)))\n",
    "\n",
    "    def __getitem__(self, i: Int) -> Int:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(tuple, TupleInt, lambda x: TupleInt(convert(x[0], Int)) + convert(x[1:], TupleInt) if x else TupleInt.EMPTY)\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _tuple_int(ti: TupleInt, ti2: TupleInt, i: Int, i2: Int, k: i64):\n",
    "    return [\n",
    "        rewrite(ti + TupleInt.EMPTY).to(ti),\n",
    "        rewrite(TupleInt(i).length()).to(Int(1)),\n",
    "        rewrite((ti + ti2).length()).to(ti.length() + ti2.length()),\n",
    "        rewrite(TupleInt(i)[Int(0)]).to(i),\n",
    "        rewrite((TupleInt(i) + ti)[Int(0)]).to(i),\n",
    "        # Rule for indexing > 0\n",
    "        rule(eq(i).to((TupleInt(i2) + ti)[Int(k)]), k > 0).then(union(i).with_(ti[Int(k - 1)])),\n",
    "    ]\n",
    "\n",
    "\n",
    "# HANDLED_FUNCTIONS = {}\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class IndexKey(Expr):\n",
    "    @classmethod\n",
    "    def tuple_int(cls, ti: TupleInt) -> IndexKey:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def int(cls, i: Int) -> IndexKey:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(tuple, IndexKey, lambda x: IndexKey.tuple_int(convert(x, TupleInt)))\n",
    "converter(int, IndexKey, lambda x: IndexKey.int(Int(x)))\n",
    "converter(Int, IndexKey, lambda x: IndexKey.int(x))\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class Device(Expr): ...\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class NDArray(Expr):\n",
    "    def __init__(self, py_array: PyObject) -> None:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(cost=100)\n",
    "    @classmethod\n",
    "    def var(cls, name: StringLike) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __array_namespace__(self, api_version=None):\n",
    "        return sys.modules[__name__]\n",
    "\n",
    "    @property\n",
    "    def ndim(self) -> Int:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def dtype(self) -> DType:\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    def device(self) -> Device:\n",
    "        ...\n",
    "\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> TupleInt:\n",
    "        ...\n",
    "\n",
    "    def bool(self) -> Bool:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __bool__(self) -> bool:\n",
    "        return bool(self.bool())\n",
    "\n",
    "    @property\n",
    "    def size(self) -> Int:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.size)\n",
    "\n",
    "    def __getitem__(self, key: IndexKey) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    def __truediv__(self, other: NDArray) -> NDArray:\n",
    "        ...\n",
    "    \n",
    "    def __sub__(self, other: NDArray) -> NDArray: ...\n",
    "\n",
    "    def __add__(self, other: NDArray) -> NDArray: ...\n",
    "\n",
    "    def __lt__(self, other: NDArray) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    def __gt__(self, other: NDArray) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def scalar_float(cls, other: Float) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def scalar_int(cls, other: Int) -> NDArray:\n",
    "        ...\n",
    "\n",
    "    @classmethod\n",
    "    def scalar_bool(cls, other: Bool) -> NDArray:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(float, NDArray, lambda x: NDArray.scalar_float(Float(x)))\n",
    "converter(int, NDArray, lambda x: NDArray.scalar_int(Int(x)))\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _ndarray(x: NDArray, b: Bool, f: Float, fi1: f64, fi2: f64):\n",
    "    return [\n",
    "        rewrite(x.ndim).to(x.shape.length()),\n",
    "        rewrite(NDArray.scalar_bool(b).bool()).to(b),\n",
    "        # TODO: Push these down to float\n",
    "        rewrite(NDArray.scalar_float(f) / NDArray.scalar_float(f)).to(NDArray.scalar_float(Float(1.0))),\n",
    "        rewrite(NDArray.scalar_float(f) - NDArray.scalar_float(f)).to(NDArray.scalar_float(Float(0.0))),\n",
    "        rewrite(NDArray.scalar_float(Float(fi1)) > NDArray.scalar_float(Float(fi2))).to(NDArray.scalar_bool(TRUE), fi1 > fi2),\n",
    "        rewrite(NDArray.scalar_float(Float(fi1)) > NDArray.scalar_float(Float(fi2))).to(NDArray.scalar_bool(FALSE), fi1 <= fi2),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class TupleNDArray(Expr):\n",
    "    EMPTY: ClassVar[TupleNDArray]\n",
    "\n",
    "    def __init__(self, head: NDArray) -> None:\n",
    "        ...\n",
    "\n",
    "    def __add__(self, other: TupleNDArray) -> TupleNDArray:\n",
    "        ...\n",
    "\n",
    "    def length(self) -> Int:\n",
    "        ...\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __len__(self) -> int:\n",
    "        return int(self.length())\n",
    "\n",
    "    @egraph.method(preserve=True)\n",
    "    def __iter__(self):\n",
    "        return iter(self[Int(i)] for i in range(len(self)))\n",
    "\n",
    "    def __getitem__(self, i: Int) -> NDArray:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(\n",
    "    tuple,\n",
    "    TupleNDArray,\n",
    "    lambda x: TupleNDArray(convert(x[0], NDArray)) + convert(x[1:], TupleNDArray) if x else TupleNDArray.EMPTY,\n",
    ")\n",
    "converter(list, TupleNDArray, lambda x: convert(tuple(x), TupleNDArray))\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _tuple_ndarray(ti: TupleNDArray, ti2: TupleNDArray, n: NDArray, i: Int, i2: Int, k: i64):\n",
    "    return [\n",
    "        rewrite(ti + TupleNDArray.EMPTY).to(ti),\n",
    "        rewrite(TupleNDArray(n).length()).to(Int(1)),\n",
    "        rewrite((ti + ti2).length()).to(ti.length() + ti2.length()),\n",
    "        # rewrite(TupleNDArray(n)[Int(0)]).to(n),\n",
    "        # rewrite((TupleNDArray(n) + ti)[Int(0)]).to(n),\n",
    "        # Rule for indexing > 0\n",
    "        # rule(eq(i).to((TupleInt(i2) + ti)[Int(k)]), k > 0).then(union(i).with_(ti[Int(k - 1)])),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class OptionalBool(Expr):\n",
    "    none: ClassVar[OptionalBool]\n",
    "\n",
    "    @classmethod\n",
    "    def some(cls, value: Bool) -> OptionalBool:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(type(None), OptionalBool, lambda x: OptionalBool.none)\n",
    "converter(Bool, OptionalBool, lambda x: OptionalBool.some(x))\n",
    "converter(bool, OptionalBool, lambda x: OptionalBool.some(convert(x, Bool)))\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class OptionalDType(Expr):\n",
    "    none: ClassVar[OptionalDType]\n",
    "\n",
    "    @classmethod\n",
    "    def some(cls, value: DType) -> OptionalDType:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(type(None), OptionalDType, lambda x: OptionalDType.none)\n",
    "converter(DType, OptionalDType, lambda x: OptionalDType.some(x))\n",
    "\n",
    "@egraph.class_\n",
    "class OptionalDevice(Expr):\n",
    "    none: ClassVar[OptionalDevice]\n",
    "\n",
    "    @classmethod\n",
    "    def some(cls, value: Device) -> OptionalDevice:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(type(None), OptionalDevice, lambda x: OptionalDevice.none)\n",
    "converter(Device, OptionalDevice, lambda x: OptionalDevice.some(x))\n",
    "\n",
    "\n",
    "@egraph.class_\n",
    "class OptionalTupleInt(Expr):\n",
    "    none: ClassVar[OptionalTupleInt]\n",
    "\n",
    "    @classmethod\n",
    "    def some(cls, value: TupleInt) -> OptionalTupleInt:\n",
    "        ...\n",
    "\n",
    "\n",
    "converter(type(None), OptionalTupleInt, lambda x: OptionalTupleInt.none)\n",
    "converter(TupleInt, OptionalTupleInt, lambda x: OptionalTupleInt.some(x))\n",
    "converter(int, OptionalTupleInt, lambda x: OptionalTupleInt.some(TupleInt(Int(x))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def asarray(a: NDArray, dtype: OptionalDType = OptionalDType.none, copy: OptionalBool = OptionalBool.none) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _assarray(a: NDArray, d: OptionalDType, ob: OptionalBool):\n",
    "    yield rewrite(asarray(a, d, ob).ndim).to(a.ndim)  # asarray doesn't change ndim\n",
    "    yield rewrite(asarray(a)).to(a)  # asarray doesn't change to_py\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def isfinite(x: NDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def sum(x: NDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "@egraph.register\n",
    "def _sum(x: NDArray, y: NDArray, f: Float, dtype: DType):\n",
    "    return [\n",
    "        rewrite(sum(x / NDArray.scalar_float(f))).to(sum(x) / NDArray.scalar_float(f)),\n",
    "\n",
    "    ]\n",
    "\n",
    "@egraph.function\n",
    "def reshape(x: NDArray, shape: TupleInt, copy: OptionalBool = OptionalBool.none) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _reshape(x: NDArray, y: NDArray, shape: TupleInt, copy: OptionalBool, i: Int, s: String):\n",
    "    return [\n",
    "        # dtype of result is same as input\n",
    "        rewrite(reshape(x, shape, copy).dtype).to(x.dtype),\n",
    "        # dimensions of output are the same as length of shape\n",
    "        rewrite(reshape(x, shape, copy).shape.length()).to(shape.length()),\n",
    "        # Shape of single dimensions reshape is the total number of elements\n",
    "        rewrite(reshape(x, TupleInt(Int(-1)), copy).shape).to(TupleInt(x.size)),\n",
    "        # Reshaping something with just one dimensions doesn't change the shape\n",
    "        rule(\n",
    "            eq(y).to(reshape(x, TupleInt(Int(-1)), copy)),\n",
    "            eq(x.shape).to(TupleInt(i)),\n",
    "        ).then(union(x).with_(y)),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def unique_values(x: NDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _unique_values(x: NDArray):\n",
    "    return [\n",
    "        rewrite(unique_values(unique_values(x))).to(unique_values(x)),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def concat(arrays: TupleNDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _concat(x: NDArray):\n",
    "    return [\n",
    "        rewrite(concat(TupleNDArray(x))).to(x),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def unique_counts(x: NDArray) -> TupleNDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _unique_counts(x: NDArray):\n",
    "    return [\n",
    "        rewrite(unique_counts(x).length()).to(Int(2)),\n",
    "        # Sum of all unique counts is the size of the array\n",
    "        rewrite(sum(unique_counts(x)[Int(1)])).to(NDArray.scalar_int(x.size)),\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def astype(x: NDArray, dtype: DType) -> NDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _astype(x: NDArray, dtype: DType, i: i64):\n",
    "    return [\n",
    "        rewrite(astype(x, dtype).dtype).to(dtype),\n",
    "        rewrite(sum(astype(x, dtype))).to(astype(sum(x), dtype)),\n",
    "        rewrite(astype(NDArray.scalar_int(Int(i)), float64)).to(NDArray.scalar_float(Float(f64.from_i64(i))))\n",
    "    ]\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def any(x: NDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "@egraph.function(egg_fn=\"ndarray-abs\")\n",
    "def abs(x: NDArray) -> NDArray:\n",
    "    ...\n",
    "\n",
    "@egraph.register\n",
    "def _abs(f: Float):\n",
    "    return [\n",
    "        rewrite(abs(NDArray.scalar_float(f))).to(NDArray.scalar_float(f)),\n",
    "    ]\n",
    "\n",
    "@egraph.function\n",
    "def unique_inverse(x: NDArray) -> TupleNDArray:\n",
    "    ...\n",
    "\n",
    "@egraph.register\n",
    "def _unique_inverse(x: NDArray):\n",
    "    return [\n",
    "        rewrite(unique_inverse(x).length()).to(Int(2)),\n",
    "        # Shape of unique_inverse first element is same as shape of unique_values\n",
    "        rewrite(unique_inverse(x)[Int(0)].shape).to(unique_values(x).shape),\n",
    "    ]\n",
    "\n",
    "@egraph.function\n",
    "def zeros(shape: TupleInt, dtype: OptionalDType = OptionalDType.none, device: OptionalDevice = OptionalDevice.none) -> NDArray:\n",
    "    ...\n",
    "@egraph.function\n",
    "def mean(x: NDArray, axis: OptionalTupleInt = OptionalTupleInt.none) -> NDArray: ...\n",
    "\n",
    "\n",
    "linalg = sys.modules[__name__]\n",
    "\n",
    "@egraph.function\n",
    "def svd(x: NDArray) -> TupleNDArray:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _linalg(x: NDArray):\n",
    "    return [\n",
    "        rewrite(svd(x).length()).to(Int(3)),\n",
    "    ]\n",
    "\n",
    "##\n",
    "# Interval analysis\n",
    "#\n",
    "# to analyze `any(((astype(unique_counts(NDArray.var(\"y\"))[Int(1)], DType.float64) / NDArray.scalar_float(Float(150.0))) < NDArray.scalar_int(Int(0)))).bool()``\n",
    "##\n",
    "\n",
    "@egraph.function\n",
    "def ndarray_all_greater_0(x: NDArray) -> Unit:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.function\n",
    "def ndarray_all_false(x: NDArray) -> Unit:\n",
    "    ...\n",
    "\n",
    "\n",
    "@egraph.register\n",
    "def _interval_analaysis(x: NDArray, y: NDArray, z: NDArray, dtype: DType, f: f64):\n",
    "    return [\n",
    "        rule(\n",
    "            eq(y).to(x < NDArray.scalar_int(Int(0))),\n",
    "            ndarray_all_greater_0(x),\n",
    "        ).then(ndarray_all_false(y)),\n",
    "        rule(\n",
    "            eq(y).to(any(x)),\n",
    "            ndarray_all_false(x),\n",
    "        ).then(union(y).with_(NDArray.scalar_bool(FALSE))),\n",
    "        rule(eq(y).to(unique_counts(x)[Int(1)]),).then(ndarray_all_greater_0(y)),\n",
    "        rule(eq(y).to(astype(x, dtype)), ndarray_all_greater_0(x)).then(ndarray_all_greater_0(y)),\n",
    "        rule(eq(z).to(x / y), ndarray_all_greater_0(x), ndarray_all_greater_0(y)).then(ndarray_all_greater_0(z)),\n",
    "        rule(eq(z).to(NDArray.scalar_float(Float(f))), f > 0.0).then(ndarray_all_greater_0(z)),\n",
    "    ]\n",
    "\n",
    "\n",
    "X_arr = NDArray.var(\"X\")\n",
    "y_arr = NDArray.var(\"y\")\n",
    "\n",
    "# Add values for the constants\n",
    "egraph.register(\n",
    "    rewrite(X_arr.dtype, runtime_ruleset).to(convert(X.dtype, DType)),\n",
    "    rewrite(y_arr.dtype, runtime_ruleset).to(convert(y.dtype, DType)),\n",
    "    rewrite(isfinite(sum(X_arr)).bool(), runtime_ruleset).to(TRUE),\n",
    "    rewrite(isfinite(sum(y_arr)).bool(), runtime_ruleset).to(TRUE),\n",
    "    rewrite(X_arr.shape, runtime_ruleset).to(convert(X.shape, TupleInt)),\n",
    "    rewrite(y_arr.shape, runtime_ruleset).to(convert(y.shape, TupleInt)),\n",
    "    rewrite(X_arr.size, runtime_ruleset).to(Int(X.size)),\n",
    "    rewrite(y_arr.size, runtime_ruleset).to(Int(y.size)),\n",
    "    rewrite(unique_values(y_arr).shape).to(TupleInt(Int(3))),\n",
    ")\n",
    "\n",
    "\n",
    "res = fit(X_arr, y_arr)\n",
    "\n",
    "# X_obj, y_obj = egraph.save_object(X), egraph.save_object(y)\n",
    "\n",
    "# X_arr = NDArray(X_obj)\n",
    "# y_arr = NDArray(y_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "mystnb": {
   "execution_mode": "off"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
